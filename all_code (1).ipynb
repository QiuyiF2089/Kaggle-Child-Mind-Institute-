{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2_lcbDlCu2gN"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9tY0P1tpGDH"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1RnchYrdu5cF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5SmpgEbfphmu"
   },
   "outputs": [],
   "source": [
    "# tabular data\n",
    "df_train_csv = pd.read_csv('/content/drive/My Drive/child-mind-institute-problematic-internet-use/train.csv')\n",
    "df_test_csv = pd.read_csv('/content/drive/My Drive/child-mind-institute-problematic-internet-use/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R_S5cvZwpRO3"
   },
   "outputs": [],
   "source": [
    "# accelerometer (actigraphy) series\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9c9qOBmqSIt"
   },
   "source": [
    "# Data Cleaning\n",
    "1. Tabular Data\n",
    "2. Accelerometer (actigraphy) Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NBAQAu1iq8dk"
   },
   "source": [
    "## Tabular Data\n",
    "\n",
    "1. Train\n",
    "\n",
    "  1. Delete all rows with NA for sii column.\n",
    "\n",
    "  2. Delete some of columns for train dataset to make sure train dataset features are same as test dataset.\n",
    "\n",
    "  3. Drop duplicate BMI related columns in train dataset.\n",
    "  \n",
    "  4. Convert Fitness_Endurance-Time_Mins and Fitness_Endurance into one column -- Fitness_Endurance-Time(mins) to convenient model training.\n",
    "\n",
    "  5. Delete all season related columns. It has less correlation with target variable. Besides, there are lots of missing values which cannot be made up. Finally, we deceided to delete these columns.\n",
    "\n",
    "2. Test\n",
    "\n",
    "  1. Drop duplicate BMI related columns in train dataset.\n",
    "  \n",
    "  2. Convert Fitness_Endurance-Time_Mins and Fitness_Endurance into one column -- Fitness_Endurance-Time(mins) to convenient model training.\n",
    "\n",
    "  3. Delete all season related columns. It has less correlation with target variable. Besides, there are lots of missing values which cannot be made up. Finally, we deceided to delete these columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QImiTDtjruKc"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FZZy5oA8q71T"
   },
   "outputs": [],
   "source": [
    "# delete all rows with NA for sii column\n",
    "df_train_csv_filter = df_train_csv[df_train_csv['sii'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qnOoAeS1qNmy"
   },
   "outputs": [],
   "source": [
    "# Make sure features are same at train dataset and test dataset\n",
    "common_columns = list(set(df_train_csv_filter.columns) & set(df_test_csv.columns))\n",
    "\n",
    "common_columns_train = common_columns + ['sii']\n",
    "df_train_csv_filter = df_train_csv_filter[sorted(common_columns_train)]\n",
    "\n",
    "df_test_csv = df_test_csv[sorted(common_columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p6bDcIvTrVVk"
   },
   "outputs": [],
   "source": [
    "# feature aggregation -- BMI, height, weight\n",
    "df_train_csv_filter = df_train_csv_filter.drop(columns=['BIA-BIA_BMI', 'Physical-Weight', 'Physical-Height'])\n",
    "\n",
    "# convert time (mins)\n",
    "df_train_csv_filter['Fitness_Endurance-Time'] = df_train_csv_filter['Fitness_Endurance-Time_Mins'] + df_train_csv_filter['Fitness_Endurance-Time_Sec']/60\n",
    "df_train_csv_filter = df_train_csv_filter.drop(columns=['Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec'])\n",
    "\n",
    "# delete all season columns\n",
    "season_columns = [col for col in df_train_csv_filter.columns if \"Season\" in col]\n",
    "df_train_csv_filter = df_train_csv_filter.drop(columns=season_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxCRBp8Yr262"
   },
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QwWoqIr-rZN8"
   },
   "outputs": [],
   "source": [
    "# feature aggregation -- BMI, height, weight\n",
    "df_test_csv = df_test_csv.drop(columns=['BIA-BIA_BMI', 'Physical-Weight', 'Physical-Height'])\n",
    "\n",
    "# convert time (mins)\n",
    "df_test_csv['Fitness_Endurance-Time'] = df_test_csv['Fitness_Endurance-Time_Mins'] + df_test_csv['Fitness_Endurance-Time_Sec']/60\n",
    "df_test_csv = df_test_csv.drop(columns=['Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec'])\n",
    "\n",
    "# delete all season columns\n",
    "season_columns = [col for col in df_test_csv.columns if \"Season\" in col]\n",
    "df_test_csv = df_test_csv.drop(columns=season_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWN7L5gWtxEw"
   },
   "source": [
    "## Accelerometer (actigraphy) Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yed1VKKTtwl0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBsQ14LPt7QF"
   },
   "source": [
    "# Final Data Version\n",
    "\n",
    "Finally, we merged 2 type of data together. Besides, after consideration, created 3 version data and use them for the model training process.\n",
    "\n",
    "1.\n",
    "\n",
    "2.\n",
    "\n",
    "3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aFgcHoDzt6g_"
   },
   "outputs": [],
   "source": [
    "df_train_raw_features=df_train_csv_filter.merge(train_features,on='id')\n",
    "df_train_raw_stat=df_train_csv_filter.merge(trian_stat,on='id')\n",
    "df_train_raw_time_series=df_train_csv_filter.merge(train_time_series,on='id')\n",
    "df_test_raw_features=df_test_csv.merge(test_features,on='id')\n",
    "df_test_raw_stat=df_test_csv.merge(test_stat,on='id')\n",
    "df_test_raw_time_series=df_test_csv.merge(test_time_series,on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "inJHBXPrt2ht"
   },
   "outputs": [],
   "source": [
    "# df_train_raw_features.to_csv('/content/drive/My Drive/child-mind/Archive/df_train_raw_features.csv')\n",
    "# df_train_raw_stat.to_csv('/content/drive/My Drive/child-mind/Archive/df_train_raw_stat.csv')\n",
    "# df_train_raw_time_series.to_csv('/content/drive/My Drive/child-mind/Archive/df_train_raw_time_series.csv')\n",
    "# df_test_raw_features.to_csv('/content/drive/My Drive/child-mind/Archive/df_test_raw_features.csv')\n",
    "# df_test_raw_stat.to_csv('/content/drive/My Drive/child-mind/Archive/df_test_raw_stat.csv')\n",
    "# df_test_raw_time_series.to_csv('/content/drive/My Drive/child-mind/Archive/df_test_raw_time_series.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6_0tutDujB9"
   },
   "source": [
    "# Model Training\n",
    "\n",
    "For each version data, we test below models:\n",
    "1. Boosting\n",
    "  1. XGBoost\n",
    "\n",
    "  2. LightGBM\n",
    "\n",
    "  3. CatBoost\n",
    "2. Stacking -> XGBoost + CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vymeld1KwkXq"
   },
   "source": [
    "## df_train_raw_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3kdQpczILfB"
   },
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qFZLXO9TwkEl"
   },
   "outputs": [],
   "source": [
    "# Features and target\n",
    "X = df_train_raw_features.drop(columns=['id', 'Unnamed: 0', 'sii', 'Unnamed: 0.1'], axis=1)\n",
    "y = df_train_raw_features['sii']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K3dFJTEjw1X9"
   },
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "\n",
    "# XGBoost\n",
    "xgb_clf = XGBClassifier(\n",
    "    objective='multi:softprob',\n",
    "    num_class=4,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# LightGBM\n",
    "lgb_clf = LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    num_class=4,\n",
    "    class_weight=class_weights_dict,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# CatBoost\n",
    "cat_clf = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    loss_function='MultiClass',\n",
    "    verbose=100,\n",
    "    class_weights=class_weights_dict,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-XFMZpa-w6c5"
   },
   "outputs": [],
   "source": [
    "# Train the Models\n",
    "sample_weights = y_train.map(class_weights_dict)\n",
    "xgb_clf.fit(\n",
    "    X_train, y_train,\n",
    "    sample_weight=sample_weights,\n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "    verbose=True\n",
    ")\n",
    "lgb_clf.fit(X_train, y_train)\n",
    "cat_clf.fit(X_train, y_train, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RN5rytaww-Vj"
   },
   "outputs": [],
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "# XGBoost\n",
    "y_pred_xgb = xgb_clf.predict(X_test)\n",
    "\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost Accuracy: {accuracy_xgb:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_xgb))\n",
    "\n",
    "# LightGBM\n",
    "y_pred_lgb = lgb_clf.predict(X_test)\n",
    "\n",
    "accuracy_lgb = accuracy_score(y_test, y_pred_lgb)\n",
    "print(f\"LightGBM Accuracy: {accuracy_lgb:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_lgb))\n",
    "\n",
    "# CatBoost\n",
    "y_pred_cat = cat_clf.predict(X_test)\n",
    "\n",
    "accuracy_cat = accuracy_score(y_test, y_pred_cat)\n",
    "print(f\"CatBoost Accuracy: {accuracy_cat:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "glCyc9zew_Lt"
   },
   "outputs": [],
   "source": [
    "# # Hyperparameter Tuning\n",
    "\n",
    "# # XGBoost\n",
    "\n",
    "# # Define parameter grid\n",
    "# xgb_param_grid = {\n",
    "#     'n_estimators': [100, 300, 500],\n",
    "#     'max_depth': [3, 6, 9],\n",
    "#     'learning_rate': [0.01, 0.1, 0.2],\n",
    "#     'subsample': [0.6, 0.8, 1.0]\n",
    "# }\n",
    "\n",
    "# # Initialize GridSearchCV\n",
    "# xgb_grid = GridSearchCV(\n",
    "#     estimator=xgb_clf,\n",
    "#     param_grid=xgb_param_grid,\n",
    "#     scoring='accuracy',\n",
    "#     cv=5,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# # LightGBM\n",
    "# lgb_param_grid = {\n",
    "#     'n_estimators': [100, 300, 500],\n",
    "#     'num_leaves': [31, 50, 100],\n",
    "#     'learning_rate': [0.01, 0.1, 0.2],\n",
    "#     'subsample': [0.6, 0.8, 1.0]\n",
    "# }\n",
    "\n",
    "\n",
    "# lgb_grid = GridSearchCV(\n",
    "#     estimator=lgb_clf,\n",
    "#     param_grid=lgb_param_grid,\n",
    "#     scoring='accuracy',\n",
    "#     cv=5,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# lgb_grid.fit(X_train, y_train)\n",
    "\n",
    "# print(\"LightGBM Best Parameters:\", lgb_grid.best_params_)\n",
    "# print(\"LightGBM Best CV Accuracy:\", lgb_grid.best_score_)\n",
    "\n",
    "# y_pred_lgb_best = lgb_grid.best_estimator_.predict(X_test)\n",
    "# accuracy_lgb_best = accuracy_score(y_test, y_pred_lgb_best)\n",
    "# print(f\"LightGBM Best Accuracy: {accuracy_lgb_best:.4f}\")\n",
    "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred_lgb_best))\n",
    "\n",
    "# # CatBoost\n",
    "\n",
    "# cat_param_grid = {\n",
    "#     'depth': [4, 6, 8],\n",
    "#     'learning_rate': [0.01, 0.1, 0.2],\n",
    "#     'iterations': [500, 1000],\n",
    "#     'l2_leaf_reg': [1, 3, 5]\n",
    "# }\n",
    "\n",
    "# cat_grid = GridSearchCV(\n",
    "#     estimator=cat_clf,\n",
    "#     param_grid=cat_param_grid,\n",
    "#     scoring='accuracy',\n",
    "#     cv=5,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# cat_grid.fit(X_train, y_train)\n",
    "\n",
    "# print(\"CatBoost Best Parameters:\", cat_grid.best_params_)\n",
    "# print(\"CatBoost Best CV Accuracy:\", cat_grid.best_score_)\n",
    "\n",
    "# y_pred_cat_best = cat_grid.best_estimator_.predict(X_test)\n",
    "# accuracy_cat_best = accuracy_score(y_test, y_pred_cat_best)\n",
    "# print(f\"CatBoost Best Accuracy: {accuracy_cat_best:.4f}\")\n",
    "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred_cat_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56o5vsAYIpd3"
   },
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dEro_wfeIsHm"
   },
   "outputs": [],
   "source": [
    "threshold = 0.7\n",
    "cols_before = df_train_raw_features.shape[1]\n",
    "df_train_raw_features = df_train_raw_features.loc[:, df_train_raw_features.isnull().mean() < (1 - threshold)]\n",
    "cols_after = df_train_raw_features.shape[1]\n",
    "\n",
    "# # XGBoost\n",
    "# xgb_clf = XGBClassifier(\n",
    "#     objective='multi:softprob',\n",
    "#     num_class=len(classes),\n",
    "#     use_label_encoder=False,\n",
    "#     eval_metric='mlogloss',\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# # CatBoost\n",
    "# cat_clf = CatBoostClassifier(\n",
    "#     iterations=1000,\n",
    "#     learning_rate=0.1,\n",
    "#     depth=6,\n",
    "#     loss_function='MultiClass',\n",
    "#     verbose=100,\n",
    "#     class_weights=class_weights_dict,\n",
    "#     random_seed=42\n",
    "# )\n",
    "\n",
    "meta_clf = LogisticRegression(\n",
    "    solver='lbfgs',\n",
    "    multi_class='multinomial',\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "base_estimators = [\n",
    "    ('xgb', xgb_clf),\n",
    "    ('cat', cat_clf)\n",
    "]\n",
    "\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=base_estimators,\n",
    "    final_estimator=meta_clf,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    passthrough=False,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_stacking = stacking_clf.predict(X_test)\n",
    "print(\"stacking classification reporting:\\n\", classification_report(y_test, y_pred_stacking, target_names=[f\"类别{cls}\" for cls in classes]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XuyRXE0rxBn8"
   },
   "source": [
    "## df_train_raw_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7U19oyiHI6ZX"
   },
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TwvbqOF7xK9z"
   },
   "outputs": [],
   "source": [
    "# Features and target\n",
    "X = df_train_raw_stat.drop(columns=['id', 'Unnamed: 0', 'sii', 'Unnamed: 0.1'], axis=1)\n",
    "y = df_train_raw_stat['sii']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iEwJVRK8xWBo"
   },
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "\n",
    "# XGBoost\n",
    "xgb_clf = XGBClassifier(\n",
    "    objective='multi:softprob',\n",
    "    num_class=4,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# LightGBM\n",
    "lgb_clf = LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    num_class=4,\n",
    "    class_weight=class_weights_dict,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# CatBoost\n",
    "cat_clf = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    loss_function='MultiClass',\n",
    "    verbose=100,\n",
    "    class_weights=class_weights_dict,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4w17JlVgxXlQ"
   },
   "outputs": [],
   "source": [
    "# Train the Models\n",
    "sample_weights = y_train.map(class_weights_dict)\n",
    "xgb_clf.fit(\n",
    "    X_train, y_train,\n",
    "    sample_weight=sample_weights,\n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "    verbose=True\n",
    ")\n",
    "lgb_clf.fit(X_train, y_train)\n",
    "cat_clf.fit(X_train, y_train, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EHvJk604xZKT"
   },
   "outputs": [],
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "# XGBoost\n",
    "y_pred_xgb = xgb_clf.predict(X_test)\n",
    "\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost Accuracy: {accuracy_xgb:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_xgb))\n",
    "\n",
    "# LightGBM\n",
    "y_pred_lgb = lgb_clf.predict(X_test)\n",
    "\n",
    "accuracy_lgb = accuracy_score(y_test, y_pred_lgb)\n",
    "print(f\"LightGBM Accuracy: {accuracy_lgb:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_lgb))\n",
    "\n",
    "# CatBoost\n",
    "y_pred_cat = cat_clf.predict(X_test)\n",
    "\n",
    "accuracy_cat = accuracy_score(y_test, y_pred_cat)\n",
    "print(f\"CatBoost Accuracy: {accuracy_cat:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0B7Pg96CxaiM"
   },
   "outputs": [],
   "source": [
    "# # Hyperparameter Tuning\n",
    "\n",
    "# # XGBoost\n",
    "\n",
    "# # Define parameter grid\n",
    "# xgb_param_grid = {\n",
    "#     'n_estimators': [100, 300, 500],\n",
    "#     'max_depth': [3, 6, 9],\n",
    "#     'learning_rate': [0.01, 0.1, 0.2],\n",
    "#     'subsample': [0.6, 0.8, 1.0]\n",
    "# }\n",
    "\n",
    "# # Initialize GridSearchCV\n",
    "# xgb_grid = GridSearchCV(\n",
    "#     estimator=xgb_clf,\n",
    "#     param_grid=xgb_param_grid,\n",
    "#     scoring='accuracy',\n",
    "#     cv=5,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# # LightGBM\n",
    "# lgb_param_grid = {\n",
    "#     'n_estimators': [100, 300, 500],\n",
    "#     'num_leaves': [31, 50, 100],\n",
    "#     'learning_rate': [0.01, 0.1, 0.2],\n",
    "#     'subsample': [0.6, 0.8, 1.0]\n",
    "# }\n",
    "\n",
    "\n",
    "# lgb_grid = GridSearchCV(\n",
    "#     estimator=lgb_clf,\n",
    "#     param_grid=lgb_param_grid,\n",
    "#     scoring='accuracy',\n",
    "#     cv=5,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# lgb_grid.fit(X_train, y_train)\n",
    "\n",
    "# print(\"LightGBM Best Parameters:\", lgb_grid.best_params_)\n",
    "# print(\"LightGBM Best CV Accuracy:\", lgb_grid.best_score_)\n",
    "\n",
    "# y_pred_lgb_best = lgb_grid.best_estimator_.predict(X_test)\n",
    "# accuracy_lgb_best = accuracy_score(y_test, y_pred_lgb_best)\n",
    "# print(f\"LightGBM Best Accuracy: {accuracy_lgb_best:.4f}\")\n",
    "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred_lgb_best))\n",
    "\n",
    "# # CatBoost\n",
    "\n",
    "# cat_param_grid = {\n",
    "#     'depth': [4, 6, 8],\n",
    "#     'learning_rate': [0.01, 0.1, 0.2],\n",
    "#     'iterations': [500, 1000],\n",
    "#     'l2_leaf_reg': [1, 3, 5]\n",
    "# }\n",
    "\n",
    "# cat_grid = GridSearchCV(\n",
    "#     estimator=cat_clf,\n",
    "#     param_grid=cat_param_grid,\n",
    "#     scoring='accuracy',\n",
    "#     cv=5,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# cat_grid.fit(X_train, y_train)\n",
    "\n",
    "# print(\"CatBoost Best Parameters:\", cat_grid.best_params_)\n",
    "# print(\"CatBoost Best CV Accuracy:\", cat_grid.best_score_)\n",
    "\n",
    "# y_pred_cat_best = cat_grid.best_estimator_.predict(X_test)\n",
    "# accuracy_cat_best = accuracy_score(y_test, y_pred_cat_best)\n",
    "# print(f\"CatBoost Best Accuracy: {accuracy_cat_best:.4f}\")\n",
    "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred_cat_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGTzSR_eI32S"
   },
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cFWli6h2I2uB"
   },
   "outputs": [],
   "source": [
    "threshold = 0.7\n",
    "cols_before = df_train_raw_stat.shape[1]\n",
    "df_train_raw_stat = df_train_raw_stat.loc[:, df_train_raw_stat.isnull().mean() < (1 - threshold)]\n",
    "cols_after = df_train_raw_stat.shape[1]\n",
    "\n",
    "# # XGBoost\n",
    "# xgb_clf = XGBClassifier(\n",
    "#     objective='multi:softprob',\n",
    "#     num_class=len(classes),\n",
    "#     use_label_encoder=False,\n",
    "#     eval_metric='mlogloss',\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# # CatBoost\n",
    "# cat_clf = CatBoostClassifier(\n",
    "#     iterations=1000,\n",
    "#     learning_rate=0.1,\n",
    "#     depth=6,\n",
    "#     loss_function='MultiClass',\n",
    "#     verbose=100,\n",
    "#     class_weights=class_weights_dict,\n",
    "#     random_seed=42\n",
    "# )\n",
    "\n",
    "meta_clf = LogisticRegression(\n",
    "    solver='lbfgs',\n",
    "    multi_class='multinomial',\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "base_estimators = [\n",
    "    ('xgb', xgb_clf),\n",
    "    ('cat', cat_clf)\n",
    "]\n",
    "\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=base_estimators,\n",
    "    final_estimator=meta_clf,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    passthrough=False,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_stacking = stacking_clf.predict(X_test)\n",
    "print(\"stacking classification reporting:\\n\", classification_report(y_test, y_pred_stacking, target_names=[f\"类别{cls}\" for cls in classes]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q48WAHAPu_G_"
   },
   "source": [
    "## df_train_raw_time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBVLfTWdI-ZX"
   },
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e5aV_uOYvoit"
   },
   "outputs": [],
   "source": [
    "# Features and target\n",
    "X = df_train_raw_time_series.drop(columns=['id', 'Unnamed: 0', 'sii', 'Unnamed: 0.1'], axis=1)\n",
    "y = df_train_raw_time_series['sii']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XTUxZOrPvzT9"
   },
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "\n",
    "# XGBoost\n",
    "xgb_clf = XGBClassifier(\n",
    "    objective='multi:softprob',\n",
    "    num_class=4,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# LightGBM\n",
    "lgb_clf = LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    num_class=4,\n",
    "    class_weight=class_weights_dict,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# CatBoost\n",
    "cat_clf = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    loss_function='MultiClass',\n",
    "    verbose=100,\n",
    "    class_weights=class_weights_dict,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "13TB9jnDv9XM"
   },
   "outputs": [],
   "source": [
    "# Train the Models\n",
    "sample_weights = y_train.map(class_weights_dict)\n",
    "xgb_clf.fit(\n",
    "    X_train, y_train,\n",
    "    sample_weight=sample_weights,\n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "    verbose=True\n",
    ")\n",
    "lgb_clf.fit(X_train, y_train)\n",
    "cat_clf.fit(X_train, y_train, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lynBlsKDu-to"
   },
   "outputs": [],
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "# XGBoost\n",
    "y_pred_xgb = xgb_clf.predict(X_test)\n",
    "\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost Accuracy: {accuracy_xgb:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_xgb))\n",
    "\n",
    "# LightGBM\n",
    "y_pred_lgb = lgb_clf.predict(X_test)\n",
    "\n",
    "accuracy_lgb = accuracy_score(y_test, y_pred_lgb)\n",
    "print(f\"LightGBM Accuracy: {accuracy_lgb:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_lgb))\n",
    "\n",
    "# CatBoost\n",
    "y_pred_cat = cat_clf.predict(X_test)\n",
    "\n",
    "accuracy_cat = accuracy_score(y_test, y_pred_cat)\n",
    "print(f\"CatBoost Accuracy: {accuracy_cat:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1TVuaWjNux5f"
   },
   "outputs": [],
   "source": [
    "# # Hyperparameter Tuning\n",
    "\n",
    "# # XGBoost\n",
    "\n",
    "# # Define parameter grid\n",
    "# xgb_param_grid = {\n",
    "#     'n_estimators': [100, 300, 500],\n",
    "#     'max_depth': [3, 6, 9],\n",
    "#     'learning_rate': [0.01, 0.1, 0.2],\n",
    "#     'subsample': [0.6, 0.8, 1.0]\n",
    "# }\n",
    "\n",
    "# # Initialize GridSearchCV\n",
    "# xgb_grid = GridSearchCV(\n",
    "#     estimator=xgb_clf,\n",
    "#     param_grid=xgb_param_grid,\n",
    "#     scoring='accuracy',\n",
    "#     cv=5,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# # LightGBM\n",
    "# lgb_param_grid = {\n",
    "#     'n_estimators': [100, 300, 500],\n",
    "#     'num_leaves': [31, 50, 100],\n",
    "#     'learning_rate': [0.01, 0.1, 0.2],\n",
    "#     'subsample': [0.6, 0.8, 1.0]\n",
    "# }\n",
    "\n",
    "\n",
    "# lgb_grid = GridSearchCV(\n",
    "#     estimator=lgb_clf,\n",
    "#     param_grid=lgb_param_grid,\n",
    "#     scoring='accuracy',\n",
    "#     cv=5,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# lgb_grid.fit(X_train, y_train)\n",
    "\n",
    "# print(\"LightGBM Best Parameters:\", lgb_grid.best_params_)\n",
    "# print(\"LightGBM Best CV Accuracy:\", lgb_grid.best_score_)\n",
    "\n",
    "# y_pred_lgb_best = lgb_grid.best_estimator_.predict(X_test)\n",
    "# accuracy_lgb_best = accuracy_score(y_test, y_pred_lgb_best)\n",
    "# print(f\"LightGBM Best Accuracy: {accuracy_lgb_best:.4f}\")\n",
    "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred_lgb_best))\n",
    "\n",
    "# # CatBoost\n",
    "\n",
    "# cat_param_grid = {\n",
    "#     'depth': [4, 6, 8],\n",
    "#     'learning_rate': [0.01, 0.1, 0.2],\n",
    "#     'iterations': [500, 1000],\n",
    "#     'l2_leaf_reg': [1, 3, 5]\n",
    "# }\n",
    "\n",
    "# cat_grid = GridSearchCV(\n",
    "#     estimator=cat_clf,\n",
    "#     param_grid=cat_param_grid,\n",
    "#     scoring='accuracy',\n",
    "#     cv=5,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# cat_grid.fit(X_train, y_train)\n",
    "\n",
    "# print(\"CatBoost Best Parameters:\", cat_grid.best_params_)\n",
    "# print(\"CatBoost Best CV Accuracy:\", cat_grid.best_score_)\n",
    "\n",
    "# y_pred_cat_best = cat_grid.best_estimator_.predict(X_test)\n",
    "# accuracy_cat_best = accuracy_score(y_test, y_pred_cat_best)\n",
    "# print(f\"CatBoost Best Accuracy: {accuracy_cat_best:.4f}\")\n",
    "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred_cat_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFh8MzsjJBIX"
   },
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LqXVruQqJDzF"
   },
   "outputs": [],
   "source": [
    "threshold = 0.7\n",
    "cols_before = df_train_raw_time_series.shape[1]\n",
    "df_train_raw_time_series = df_train_raw_time_series.loc[:, df_train_raw_time_series.isnull().mean() < (1 - threshold)]\n",
    "cols_after = df_train_raw_time_series.shape[1]\n",
    "\n",
    "# # XGBoost\n",
    "# xgb_clf = XGBClassifier(\n",
    "#     objective='multi:softprob',\n",
    "#     num_class=len(classes),\n",
    "#     use_label_encoder=False,\n",
    "#     eval_metric='mlogloss',\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# # CatBoost\n",
    "# cat_clf = CatBoostClassifier(\n",
    "#     iterations=1000,\n",
    "#     learning_rate=0.1,\n",
    "#     depth=6,\n",
    "#     loss_function='MultiClass',\n",
    "#     verbose=100,\n",
    "#     class_weights=class_weights_dict,\n",
    "#     random_seed=42\n",
    "# )\n",
    "\n",
    "meta_clf = LogisticRegression(\n",
    "    solver='lbfgs',\n",
    "    multi_class='multinomial',\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "base_estimators = [\n",
    "    ('xgb', xgb_clf),\n",
    "    ('cat', cat_clf)\n",
    "]\n",
    "\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=base_estimators,\n",
    "    final_estimator=meta_clf,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    passthrough=False,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_stacking = stacking_clf.predict(X_test)\n",
    "print(\"stacking classification reporting:\\n\", classification_report(y_test, y_pred_stacking, target_names=[f\"类别{cls}\" for cls in classes]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REyC_naoxpQr"
   },
   "source": [
    "## Test Data\n",
    "\n",
    "After comparison, we found xx model's performance best. So, we use XX on test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K8M31Z6-x6Bs"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "test_data = pd.read_csv(\"df_train_raw_features.csv\")\n",
    "id=test_data['id']\n",
    "\n",
    "test_data = test_data.drop(columns=['id', 'Unnamed: 0.1', 'Unnamed: 0'], errors='ignore')\n",
    "test_data= test_data.drop(columns=high_missing_cols)\n",
    "test_data = test_data.drop(columns=['sii'])\n",
    "\n",
    "test_data_imputed = pd.DataFrame(imputer.transform(test_data), columns=test_data.columns)\n",
    "\n",
    "cat_features = test_data_imputed.select_dtypes(include=['object']).columns\n",
    "for col in cat_features:\n",
    "    test_data_imputed[col] = LabelEncoder().fit_transform(test_data_imputed[col])\n",
    "\n",
    "num_features = test_data_imputed.select_dtypes(include=['float64', 'int64']).columns\n",
    "test_data_scaled = pd.DataFrame(scaler.transform(test_data_imputed), columns=test_data_imputed.columns)\n",
    "print(\"Test data cleaned successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p6uJK9oyJ-zS"
   },
   "outputs": [],
   "source": [
    "test_preds = stacking_model.predict(test_data_scaled)\n",
    "\n",
    "test_data['sii_prediction'] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_PTV4sVtKAhA"
   },
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame({\n",
    "    'id': id,\n",
    "    'sii_prediction': test_data['sii_prediction']\n",
    "})\n",
    "\n",
    "print(result_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w7rN5ZSsKJTk"
   },
   "outputs": [],
   "source": [
    "result_df.to_csv(\"final_predictions.csv\", index=False)\n",
    "print(\"Final DataFrame saved to 'final_predictions.csv'\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
